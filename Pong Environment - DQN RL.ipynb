{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame # import needed to run next few cells\n",
    "# !pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other required packages \n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "from random import choice\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747adf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create paddle and update position\n",
    "\n",
    "class Player(pygame.sprite.Sprite):\n",
    "    # paddle class extends Sprite class in Pygame\n",
    "    \n",
    "    def __init__(self, color, width, height):\n",
    "        # parent class Sprite constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # set color, width and height of paddle\n",
    "        self.image = pygame.Surface([width, height])\n",
    "        self.image.fill((0,0,0))\n",
    "        self.image.set_colorkey((0,0,0))\n",
    " \n",
    "        # Draw the paddle \n",
    "        pygame.draw.rect(self.image, color, [0, 0, width, height])\n",
    "        \n",
    "        # Fetch the rectangle object\n",
    "        self.rect = self.image.get_rect()\n",
    "        \n",
    "    def moveUp(self, pixels):\n",
    "        self.rect.y -= pixels \n",
    "        # check that paddle does not go off the screen\n",
    "        if self.rect.y < 0:\n",
    "            self.rect.y = 0\n",
    "          \n",
    "    def moveDown(self, pixels):\n",
    "        self.rect.y += pixels \n",
    "        # check that paddle does not go off the screen\n",
    "        if self.rect.y > 420:\n",
    "            self.rect.y = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend Player class and create update function to follow ball\n",
    "\n",
    "class CPU(Player):\n",
    "\n",
    "    def update(self, ball):\n",
    "        self.ball = ball\n",
    "        \n",
    "        if self.rect.centery < self.ball.rect.y:\n",
    "            self.moveDown(7)\n",
    "            \n",
    "        if self.rect.centery > self.ball.rect.y:\n",
    "            self.moveUp(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend Player class and create new function to execute action 0, 1 or 2\n",
    "\n",
    "class AI(Player):\n",
    "\n",
    "    def action_update(self, action):\n",
    "        self.action = action\n",
    "        \n",
    "        if self.action == 1:\n",
    "            self.moveDown(7)\n",
    "            \n",
    "        if self.action == 2:\n",
    "            self.moveUp(7)\n",
    "            \n",
    "        if self.action == 0:\n",
    "            self.rect.y = self.rect.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc71787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create and update ball object\n",
    "\n",
    "class Ball(pygame.sprite.Sprite):\n",
    "    # ball class extends Sprite class in Pygame\n",
    "    \n",
    "    def __init__(self, color, width, height):\n",
    "        # parent class Sprite constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # set color, width and height of the ball\n",
    "        self.image = pygame.Surface([width, height])\n",
    "        self.image.fill((0,0,0))\n",
    "        self.image.set_colorkey((0,0,0))\n",
    " \n",
    "        # Draw the ball \n",
    "        pygame.draw.rect(self.image, color, [0, 0, width, height])\n",
    "        \n",
    "        # set velocity\n",
    "        self.velocity = [0,0]\n",
    "        self.velocity[0] = randint(7,8) * random.choice([-1,1])\n",
    "        self.velocity[1] = random.choice([-3, 3])\n",
    "        \n",
    "        # Fetch the rectangle object that has the dimensions of the image.\n",
    "        self.rect = self.image.get_rect()\n",
    "        \n",
    "        self.active = False\n",
    "        self.score_time = 0\n",
    "    \n",
    "    def counter(self):\n",
    "        current_time = pygame.time.get_ticks()\n",
    "            \n",
    "        if current_time - self.score_time >= 1000:\n",
    "            self.active = True\n",
    "    \n",
    "    def update(self):\n",
    "        if self.active:\n",
    "            self.rect.x += self.velocity[0]\n",
    "            self.rect.y += self.velocity[1]\n",
    "            return True\n",
    "        else:\n",
    "            self.counter()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.active = False\n",
    "        self.rect.x = 345\n",
    "        self.rect.y = 195\n",
    "        self.velocity[0] = randint(7,8) * random.choice([-1,1])\n",
    "        self.velocity[1] = random.choice([-3, 3])\n",
    "        self.score_time = pygame.time.get_ticks()\n",
    "        \n",
    "    def bounce(self, side):\n",
    "        if(side == 'cpu'):\n",
    "            self.velocity[0] = abs(self.velocity[0])\n",
    "        else:\n",
    "            self.velocity[0] = -abs(self.velocity[0])\n",
    "        self.velocity[1] = randint(4,8) * random.choice([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main Pong Environment class\n",
    "# partly built with the help of: https://www.101computing.net/pong-tutorial-using-pygame-getting-started/\n",
    "\n",
    "class PongEnv():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.black = (0,0,0)\n",
    "        self.white = (255,255,255)\n",
    "        self.red = (255, 0, 0)\n",
    "        \n",
    "        self.height = 500\n",
    "        self.width = 700\n",
    "        self.fps = 60 # set FPS to 80+ for faster training\n",
    "    \n",
    "        self.scoreCPU = 0\n",
    "        self.scoreAI = 0\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.hit = False\n",
    "        self.wait = False\n",
    "        \n",
    "        self.action_space = [0,1,2]\n",
    "        self.observation_space = np.zeros(5) # for now only for obs count\n",
    "        \n",
    "        self.screen = None\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.state = None\n",
    "        self.is_open = True\n",
    "        \n",
    "        self.paddleCPU = CPU(self.white, 10, 80)\n",
    "        self.paddleAI = AI(self.white, 10, 80)\n",
    "        self.ball = Ball(self.red,10,10)\n",
    "        \n",
    "        # list of all the sprites in the game\n",
    "        self.all_sprites_list = pygame.sprite.Group()\n",
    "        \n",
    "        # add 2 paddles and the ball to the list of spirtes\n",
    "        self.all_sprites_list.add(self.paddleCPU)\n",
    "        self.all_sprites_list.add(self.paddleAI)\n",
    "        self.all_sprites_list.add(self.ball)\n",
    "    \n",
    "    def render(self):\n",
    "        \n",
    "        import pygame\n",
    "        \n",
    "        if self.screen is None:\n",
    "            # set new window\n",
    "            pygame.init()\n",
    "            pygame.display.set_caption(\"Pong\")\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        \n",
    "        # set screen to black\n",
    "        self.screen.fill(self.black)\n",
    "        \n",
    "        # draw line for net \n",
    "        pygame.draw.line(self.screen, self.white, [349, 0], [349, 500], 5)\n",
    "\n",
    "        # draw all the sprites\n",
    "        self.all_sprites_list.draw(self.screen)\n",
    "        \n",
    "        # display all scores\n",
    "        font = pygame.font.Font(None, 74)\n",
    "        self.screen.blit(font.render(str(self.scoreCPU), 1, self.white), (250,10))\n",
    "        self.screen.blit(font.render(str(self.scoreAI), 1, self.white), (420,10))\n",
    "        \n",
    "        # update events and screen\n",
    "        pygame.event.pump()\n",
    "        pygame.display.flip()\n",
    "        \n",
    "        return self.is_open\n",
    "\n",
    "    def step(self, action):\n",
    "            \n",
    "        # update ball and paddle position and velocity\n",
    "        self.wait = self.ball.update()\n",
    "        self.paddleCPU.update(self.ball)\n",
    "\n",
    "        #Check if the ball is bouncing against any of the 4 walls:\n",
    "        if self.ball.rect.x>=690:\n",
    "            self.scoreCPU += 1\n",
    "            self.ball.reset()\n",
    "        if self.ball.rect.x<=0:\n",
    "            self.scoreAI += 1\n",
    "            self.ball.reset()\n",
    "        if self.ball.rect.y>490:\n",
    "            self.ball.velocity[1] = -self.ball.velocity[1]\n",
    "        if self.ball.rect.y<0:\n",
    "            self.ball.velocity[1] = -self.ball.velocity[1]     \n",
    "\n",
    "        #Detect collisions between the ball and the paddles\n",
    "        if(pygame.sprite.collide_mask(self.ball, self.paddleCPU)):\n",
    "            self.ball.bounce('cpu')\n",
    "\n",
    "        if(pygame.sprite.collide_mask(self.ball, self.paddleAI)):\n",
    "            self.ball.bounce(None)\n",
    "        \n",
    "        # ----- implement action and work out reward -----\n",
    "        \n",
    "        # update ai paddle using random or predicted action\n",
    "        self.paddleAI.action_update(action)\n",
    "        \n",
    "        # initialise reward\n",
    "        self.reward = 0\n",
    "        \n",
    "        if self.wait:\n",
    "            # absolute difference reward system\n",
    "            y_difference = np.abs(self.ball.rect.centery - self.paddleAI.rect.centery)\n",
    "            if y_difference == 0:\n",
    "                self.reward = 0.5\n",
    "            else:\n",
    "                self.reward = (0.5 - ((y_difference/self.height)/2))\n",
    "            \n",
    "            # normal rewards\n",
    "            if self.ball.rect.x >= 690: # if ai paddle does not hit ball\n",
    "                self.reward = -0.5\n",
    "                self.hit = False\n",
    "            if self.ball.rect.x <= 0 and self.hit == True: # if ai paddle scores point after hit\n",
    "                self.reward += 2\n",
    "            if(pygame.sprite.collide_mask(self.ball, self.paddleAI)): # if ai paddle hits ball\n",
    "                self.reward += 1\n",
    "                self.hit = True\n",
    "            if self.scoreAI == 3: # if ai wins game\n",
    "                self.reward += 5\n",
    "                \n",
    "            self.reward = np.around(self.reward, 2)\n",
    "        \n",
    "        # score of 3 wins game returns done=True\n",
    "        done = bool(self.scoreCPU > 2 or self.scoreAI > 2)\n",
    "        \n",
    "        self.state = (self.ball.velocity[0], self.ball.velocity[1], self.ball.rect.x, self.ball.rect.y, self.paddleAI.rect.y)\n",
    "        self.state = self.norm_state(self.state)\n",
    "        \n",
    "        # tick / frames per second\n",
    "        self.clock.tick(self.fps)\n",
    "        \n",
    "        return [self.reward, self.state, done]\n",
    "    \n",
    "    # normalise state values for ann training\n",
    "    def norm_state(self, arr):\n",
    "        state = np.zeros(len(arr))\n",
    "        state[0] = arr[0]/1 # velocity 0\n",
    "        state[1] = arr[1]/1 # velocity 1\n",
    "        state[2] = arr[2]/500 # ball x\n",
    "        state[3] = arr[3]/500 # ball y\n",
    "        state[4] = arr[4]/500 # paddle y\n",
    "        return state\n",
    "    \n",
    "    # reset ball and paddle posiitons and reset scores\n",
    "    def reset(self):\n",
    "        self.paddleCPU.rect.x = 20\n",
    "        self.paddleCPU.rect.y = 200\n",
    "\n",
    "        self.paddleAI.rect.x = 670\n",
    "        self.paddleAI.rect.y = 200\n",
    "        \n",
    "        self.ball.reset()\n",
    "        \n",
    "        self.state = (self.ball.velocity[0], self.ball.velocity[1], self.ball.rect.centerx, self.ball.rect.centery, self.paddleAI.rect.y)\n",
    "        self.state = self.norm_state(self.state)\n",
    "        \n",
    "        self.scoreAI = 0\n",
    "        self.scoreCPU = 0\n",
    "        \n",
    "        self.hit = False\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    # close pong environment\n",
    "    def close(self):\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_replay(model, batch_size, gamma, memory, observation_count, action_count, epoch_count):\n",
    "    batch = random.sample(memory, batch_size) # randomly sample a batch \n",
    "    batch_vector = np.array(batch, dtype=object) # convert batch to vector\n",
    "    \n",
    "    observation_t = np.zeros((batch_size, observation_count)) #observation at time t\n",
    "    observation_t_next = np.zeros((batch_size, observation_count)) #observation at time t+1\n",
    "    for i in range(len(batch_vector)): #loop through the batch and store observations at time t and t+1 in arrays\n",
    "        observation_t[i] = batch_vector[i,0]       \n",
    "        observation_t_next[i] = batch_vector[i,3]          \n",
    "    \n",
    "    with tf.device(\"gpu:0\"):\n",
    "        # predict an action using model\n",
    "        prediction_at_t = model(observation_t).numpy()                  \n",
    "        prediction_at_t_next = model(observation_t_next).numpy()       \n",
    "    \n",
    "    # feature vector and label  \n",
    "    X = []\n",
    "    y = []               \n",
    "    \n",
    "    i = 0\n",
    "    for observation_t, action, reward, _, done in batch_vector: # fetch row from the batch\n",
    "        X.append(observation_t) # append most recent observation to feature vector\n",
    "        \n",
    "        # if episode is done: target value is the reward, if not done: get target using Bellman optimality equation\n",
    "        if done:                                 \n",
    "            target = reward                     \n",
    "        else:                                    \n",
    "            target = reward + gamma * np.max(prediction_at_t_next[i])\n",
    "        \n",
    "        # update action of original state\n",
    "        prediction_at_t[i, action] = target\n",
    "        # append updates action values to label\n",
    "        y.append(prediction_at_t[i])    \n",
    "        \n",
    "        i += 1 \n",
    "    \n",
    "    X_train = np.array(X).reshape(batch_size, observation_count) \n",
    "    y_train = np.array(y)                           \n",
    "    with tf.device(\"gpu:0\"): # using GPU\n",
    "        hist = model.fit(X_train, y_train, epochs = epoch_count, verbose=0) # fit the ann model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function from\n",
    "# https://github.com/python-engineer/snake-ai-pytorch/blob/main/helper.py\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def plot(rewards):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Number of Games')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.plot(rewards)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.text(len(rewards)-1, rewards[-1], str(rewards[-1]))\n",
    "    plt.show(block=False)\n",
    "    plt.pause(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f77f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PongEnv()\n",
    "observation_count = env.observation_space.shape[0]\n",
    "action_count = len(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001 # learning rate\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(32, input_dim=observation_count, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(action_count, activation = 'linear'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []                                                \n",
    "record = 0 # keep track of best score\n",
    "episodes = 1000                                            \n",
    "gamma = 0.9                                               \n",
    "beta = 0.05                                               \n",
    "batch_size = 128                                          \n",
    "memory = deque([], maxlen=25000) # memory replay buffer set to 25000\n",
    "\n",
    "to_render = True # set to false to not render environment\n",
    "render_freq = 5 # render every 5 episodes \n",
    "\n",
    "for episode in range(episodes):\n",
    "    observation_t = env.reset()\n",
    "    observation_t = np.reshape(observation_t, [1, observation_count])\n",
    "    \n",
    "    total_reward = 0\n",
    "    epsilon = 0.5 / (1 + beta * (episode / action_count))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        rand_num = np.random.random()\n",
    "        if rand_num <= epsilon:\n",
    "            action = random.choice(env.action_space)\n",
    "        else:\n",
    "            # note: window will be open but not respond when not rendering , do not exit\n",
    "            if episode%render_freq == 0 and to_render == True: \n",
    "                env.render() # render env\n",
    "            with tf.device(\"gpu:0\"): # execute with gpu\n",
    "                action_values = model(observation_t)\n",
    "            action = np.argmax(action_values[0])\n",
    "    \n",
    "        reward, observation_t_next, done = env.step(action)\n",
    "        observation_t_next = np.reshape(observation_t_next, [1, observation_count])\n",
    "        total_reward += reward\n",
    "        memory.append((observation_t, action, reward, observation_t_next, done))\n",
    "        observation_t = observation_t_next\n",
    "    \n",
    "        if done: # if cpu or ai wins\n",
    "            rewards.append(total_reward)\n",
    "            if total_reward > record:\n",
    "                record = total_reward\n",
    "                model.save(f'pong_model_eps{episode}')\n",
    "                \n",
    "            plot(rewards)\n",
    "            \n",
    "            print(f'\\nepisode: {episode}/{episodes}, score: {total_reward}, epsilon: {epsilon}\\n')\n",
    "        \n",
    "        #  if enough experiences start function approximation\n",
    "        if len(memory) > batch_size:\n",
    "            experience_replay(model, batch_size, gamma, memory, observation_count, action_count, 2)\n",
    "\n",
    "env.close() # close environment aftet training complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bbc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cumulative_rewards\n",
    "\n",
    "cumulative_rewards = []\n",
    "for episode in range(episodes):\n",
    "    x = sum(rewards[:episode])\n",
    "    y = x/(episode+1)\n",
    "    cumulative_rewards.append(y)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Cummulative Reward over episodes')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Cummulative Reward')\n",
    "plt.plot(range(episodes), cumulative_rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2a919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# play the game with trained model\n",
    "env = PongEnv()\n",
    "observation_count = env.observation_space.shape[0]\n",
    "action_count = len(env.action_space)\n",
    "\n",
    "model_trained = keras.models.load_model('pong_model_eps739')\n",
    "\n",
    "observation = env.reset() # reset the environment to the initial state\n",
    "observation = np.reshape(observation, [1, observation_count])\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    action_values = model_trained(observation) #run observation through the ANN Q(s,a)\n",
    "    action = np.argmax(action_values[0]) # get the best action\n",
    "    reward, observation, done = env.step(action)  # execute action\n",
    "    observation = np.reshape(observation, [1, observation_count])\n",
    "env.close() # close the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot for rewards over episodes\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Rewards Graph')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.plot(range(len(rewards)),rewards)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
